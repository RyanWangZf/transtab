{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134f979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import transtab\n",
    "\n",
    "# set random seed\n",
    "transtab.random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c60011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:159: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  dataset = openml.datasets.get_dataset(dataname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml data index: 31\n",
      "load data from credit-g\n",
      "# data: 1000, # feat: 20, # cate: 11,  # bin: 2, # numerical: 7, pos rate: 0.70\n",
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:192: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:192: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:192: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:192: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:192: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:192: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:196: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in cat_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:204: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in bin_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:208: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X[bin_cols] = X[bin_cols].astype(str).applymap(lambda x: 1 if x.lower() in ['yes','true','1','t'] else 0).values\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:159: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  dataset = openml.datasets.get_dataset(dataname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml data index: 29\n",
      "load data from credit-approval\n",
      "# data: 690, # feat: 15, # cate: 9,  # bin: 0, # numerical: 6, pos rate: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:192: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab/transtab/dataset.py:196: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  for col in cat_cols: X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "/Users/lushinchen/Documents/projects/tabular/transfer_learning/transtab_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch:   2%|▏         | 1/50 [00:01<01:33,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test val_loss: 0.581661\n",
      "epoch: 0, train loss: 3.8976, lr: 0.000100, spent: 1.9 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 2/50 [00:03<01:25,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, test val_loss: 0.570522\n",
      "epoch: 1, train loss: 3.8300, lr: 0.000100, spent: 3.6 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 3/50 [00:05<01:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, test val_loss: 0.582888\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 2, train loss: 3.6956, lr: 0.000100, spent: 5.2 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 4/50 [00:06<01:17,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, test val_loss: 0.571160\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 3, train loss: 3.6500, lr: 0.000100, spent: 6.9 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 5/50 [00:08<01:14,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, test val_loss: 0.550470\n",
      "epoch: 4, train loss: 3.5801, lr: 0.000100, spent: 8.5 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 6/50 [00:10<01:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, test val_loss: 0.541281\n",
      "epoch: 5, train loss: 3.5409, lr: 0.000100, spent: 10.0 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 7/50 [00:11<01:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, test val_loss: 0.540448\n",
      "epoch: 6, train loss: 3.4926, lr: 0.000100, spent: 11.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 8/50 [00:13<01:09,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, test val_loss: 0.525315\n",
      "epoch: 7, train loss: 3.4610, lr: 0.000100, spent: 13.4 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [00:15<01:08,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, test val_loss: 0.511740\n",
      "epoch: 8, train loss: 3.3705, lr: 0.000100, spent: 15.1 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 10/50 [00:16<01:07,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, test val_loss: 0.500303\n",
      "epoch: 9, train loss: 3.3565, lr: 0.000100, spent: 16.8 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▏       | 11/50 [00:18<01:05,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, test val_loss: 0.483438\n",
      "epoch: 10, train loss: 3.2425, lr: 0.000100, spent: 18.5 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 12/50 [00:20<01:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, test val_loss: 0.473205\n",
      "epoch: 11, train loss: 3.1949, lr: 0.000100, spent: 20.2 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  26%|██▌       | 13/50 [00:21<01:03,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, test val_loss: 0.461071\n",
      "epoch: 12, train loss: 3.1088, lr: 0.000100, spent: 22.0 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 14/50 [00:23<01:02,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, test val_loss: 0.449517\n",
      "epoch: 13, train loss: 3.0645, lr: 0.000100, spent: 23.8 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 15/50 [00:25<00:58,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, test val_loss: 0.456329\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 14, train loss: 3.0103, lr: 0.000100, spent: 25.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 16/50 [00:26<00:56,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, test val_loss: 0.440254\n",
      "epoch: 15, train loss: 2.9299, lr: 0.000100, spent: 26.9 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  34%|███▍      | 17/50 [00:28<00:55,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, test val_loss: 0.445881\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 16, train loss: 2.9415, lr: 0.000100, spent: 28.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 18/50 [00:30<00:54,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, test val_loss: 0.468616\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 17, train loss: 2.9467, lr: 0.000100, spent: 30.4 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 19/50 [00:32<00:54,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, test val_loss: 0.438237\n",
      "epoch: 18, train loss: 2.8874, lr: 0.000100, spent: 32.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 20/50 [00:33<00:51,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, test val_loss: 0.458508\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 19, train loss: 2.8655, lr: 0.000100, spent: 33.9 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▏     | 21/50 [00:35<00:48,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, test val_loss: 0.445858\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 20, train loss: 2.8660, lr: 0.000100, spent: 35.5 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 22/50 [00:37<00:46,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, test val_loss: 0.461153\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 21, train loss: 2.8441, lr: 0.000100, spent: 37.1 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  46%|████▌     | 23/50 [00:38<00:44,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, test val_loss: 0.437781\n",
      "epoch: 22, train loss: 2.8362, lr: 0.000100, spent: 38.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 24/50 [00:40<00:43,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, test val_loss: 0.443411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 23, train loss: 2.7980, lr: 0.000100, spent: 40.4 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 25/50 [00:42<00:43,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, test val_loss: 0.445250\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 24, train loss: 2.7518, lr: 0.000100, spent: 42.4 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 26/50 [00:44<00:41,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, test val_loss: 0.443745\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 25, train loss: 2.7342, lr: 0.000100, spent: 44.1 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 27/50 [00:45<00:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, test val_loss: 0.456172\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch: 26, train loss: 2.7178, lr: 0.000100, spent: 45.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 28/50 [00:47<00:37,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27, test val_loss: 0.430420\n",
      "epoch: 27, train loss: 2.6967, lr: 0.000100, spent: 47.4 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  58%|█████▊    | 29/50 [00:49<00:36,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, test val_loss: 0.444035\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 28, train loss: 2.7291, lr: 0.000100, spent: 49.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 30/50 [00:50<00:34,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29, test val_loss: 0.444959\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 29, train loss: 2.6471, lr: 0.000100, spent: 51.0 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▏   | 31/50 [00:52<00:33,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, test val_loss: 0.462955\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 30, train loss: 2.6546, lr: 0.000100, spent: 52.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 32/50 [00:54<00:30,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31, test val_loss: 0.437068\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch: 31, train loss: 2.6599, lr: 0.000100, spent: 54.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 32/50 [00:55<00:31,  1.75s/it]\n",
      "\u001b[32m2024-03-08 15:41:21.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mload best at last from ./checkpoint\u001b[0m\n",
      "\u001b[32m2024-03-08 15:41:21.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1msaving model checkpoint to ./checkpoint\u001b[0m\n",
      "\u001b[32m2024-03-08 15:41:21.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mtraining complete, cost 56.1 secs.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32, test val_loss: 0.486147\n",
      "EarlyStopping counter: 5 out of 5\n",
      "early stopped\n"
     ]
    }
   ],
   "source": [
    "# load a dataset and start vanilla supervised training\n",
    "allset, trainset, valset, testset, cat_cols, num_cols, bin_cols = transtab.load_data(['credit-g', 'credit-approval'])\n",
    "\n",
    "# build transtab classifier model\n",
    "model = transtab.build_classifier(cat_cols, num_cols, bin_cols, device='cpu')\n",
    "\n",
    "# start training\n",
    "training_arguments = {\n",
    "    'num_epoch':50,\n",
    "    'eval_metric':'val_loss',\n",
    "    'eval_less_is_better':True,\n",
    "    'output_dir':'./checkpoint',\n",
    "    'batch_size':128,\n",
    "    'lr':1e-4,\n",
    "    'weight_decay':1e-4,\n",
    "    }\n",
    "transtab.train(model, trainset[0], valset[0], **training_arguments)\n",
    "\n",
    "# save model\n",
    "model.save('./ckpt/pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bdc971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-08 15:41:31.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m774\u001b[0m - \u001b[1mmissing keys: []\u001b[0m\n",
      "\u001b[32m2024-03-08 15:41:31.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1munexpected keys: []\u001b[0m\n",
      "\u001b[32m2024-03-08 15:41:31.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m776\u001b[0m - \u001b[1mload model from ./ckpt/pretrained\u001b[0m\n",
      "\u001b[32m2024-03-08 15:41:31.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m222\u001b[0m - \u001b[1mload feature extractor from ./ckpt/pretrained/extractor/extractor.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# now let's use another data and try to leverage the pretrained model for finetuning\n",
    "# here we have loaded the required data `credit-approval` before, no need to load again.\n",
    "\n",
    "# load the pretrained model\n",
    "model.load('./ckpt/pretrained')\n",
    "\n",
    "# update model's categorical/numerical/binary column dict\n",
    "# need to specify the number of classes if the new dataset has different # of classes from the \n",
    "# pretrained one.\n",
    "model.update({'cat':cat_cols,'num':num_cols,'bin':bin_cols, 'num_class':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f399d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▏         | 1/50 [00:00<00:36,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test auc: 0.918615\n",
      "epoch: 0, train loss: 1.7609, lr: 0.000200, spent: 0.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 2/50 [00:01<00:28,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, test auc: 0.914286\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 1, train loss: 1.7883, lr: 0.000200, spent: 1.2 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 3/50 [00:01<00:29,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, test auc: 0.915152\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 2, train loss: 1.6351, lr: 0.000200, spent: 1.9 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 4/50 [00:02<00:28,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, test auc: 0.919481\n",
      "epoch: 3, train loss: 1.5851, lr: 0.000200, spent: 2.5 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 5/50 [00:03<00:27,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, test auc: 0.919481\n",
      "epoch: 4, train loss: 1.6347, lr: 0.000200, spent: 3.1 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 6/50 [00:03<00:26,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, test auc: 0.912554\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 5, train loss: 1.5367, lr: 0.000200, spent: 3.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 7/50 [00:04<00:24,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, test auc: 0.912554\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 6, train loss: 1.5744, lr: 0.000200, spent: 4.2 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 8/50 [00:04<00:24,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, test auc: 0.912554\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 7, train loss: 1.5259, lr: 0.000200, spent: 4.8 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [00:05<00:22,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, test auc: 0.913420\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch: 8, train loss: 1.5106, lr: 0.000200, spent: 5.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [00:05<00:26,  1.55it/s]\n",
      "\u001b[32m2024-03-08 15:42:21.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mload best at last from ./checkpoint\u001b[0m\n",
      "\u001b[32m2024-03-08 15:42:21.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1msaving model checkpoint to ./checkpoint\u001b[0m\n",
      "\u001b[32m2024-03-08 15:42:21.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mtraining complete, cost 5.9 secs.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, test auc: 0.910823\n",
      "EarlyStopping counter: 5 out of 5\n",
      "early stopped\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "training_arguments = {\n",
    "    'num_epoch':50,\n",
    "    'eval_metric':'auc',\n",
    "    'eval_less_is_better':False,\n",
    "    'output_dir':'./checkpoint',\n",
    "    'batch_size':128,\n",
    "    'lr':2e-4,\n",
    "    }\n",
    "\n",
    "transtab.train(model, trainset[1], valset[1], **training_arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa87021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8639557164147328\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "x_test, y_test = testset[1]\n",
    "ypred = transtab.predict(model, x_test, y_test)\n",
    "transtab.evaluate(ypred, y_test, metric='auc')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf1d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transtab_env",
   "language": "python",
   "name": "transtab_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f00ab411e3cfe281b54106f98420bd06c3920b043d7b3741a63d2a4ac576305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
